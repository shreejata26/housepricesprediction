# -*- coding: utf-8 -*-
"""housing_price_prediction_lstm.ipynb

Automatically generated by Colaboratory.

"""

from __future__ import print_function
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

import keras
from keras import metrics
from keras import regularizers
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Activation
from keras.layers import LSTM
from keras.optimizers import Adam, RMSprop
from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint
from keras.utils import plot_model
from keras.models import load_model

# Reading the input file containing the features and target variable

# from google.colab import files
# uploaded = files.upload()
# import io
# data = pd.read_csv(io.StringIO(uploaded['data.csv'].decode('utf-8')))
data = pd.read_csv('Code_no_agg/data/data.csv')

# Removing the unwanted features

relevant_columns = np.array(data.columns.isin(['GEO', 'REF_DATE', 'DGUID', 'total_house_land'])) #+ np.array(data.dtypes != object)
input = data.loc[:, relevant_columns]
print(input.columns)

# DGUID of province we are interested in predicting the housing index for.

province_dguid = ['2016A000235', '2016A000259', '2016A000224', '2016A000248', '2016A000212', '2016A000246', '2016A000247']
# ON, BC, QB, AL, NS, MT, SK

# Filtering the data for provinces of interest and sorting it based on province and date
# One-hot encode the province name

input1 = input[input['DGUID'].isin(province_dguid)]
province_data = pd.concat([input1, pd.get_dummies(input1.GEO, prefix='Province')], axis=1).sort_values(['GEO', 'REF_DATE'])
print(province_data.columns)

# Storing list of columns to be used as features and target for our model into feature_columns and target_column.

feature_columns = province_data.columns[np.array(province_data.dtypes != object)]
target_column = 'total_house_land'
print(feature_columns)

# Droping the data if target variable is null

def drop_data(df):
    tmp = df.dropna(subset=[target_column])
    return tmp

# Droping the data containing the null for target variable

result = drop_data(province_data)
print(result.info())

# Creating a time-series for training the lstm model
# look_back variable contains the time series length
# Predict housing index given housing index value and one-hot encoded province name for last n=look_back months
# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/

def create_dataset(df, look_back=1):
  dataX, dataY, dataP, dataT, dataD = [], [], [], [], []
  for dguid in province_dguid:
    dataset = df[df['DGUID']== dguid]
    for i in range(len(dataset)-look_back):
      a = dataset[feature_columns][i:(i+look_back)]
      dataX.append(np.array(a))
      dataY.append(np.array(dataset[target_column].iloc[i + look_back]))
      dataT.append(np.array(dataset['REF_DATE'].iloc[i + look_back]))
      dataP.append(np.array(dataset['GEO'].iloc[i + look_back]))
      dataD.append(np.array(dataset['DGUID'].iloc[i + look_back]))
  return np.array(dataX), np.array(dataY), np.array(dataT), np.array(dataP), np.array(dataD)


look_back = 6
dataX, dataY, dataT, dataP, dataD = create_dataset(result, look_back)

last_idx = len(dataX)-1
print(dataX[last_idx], dataY[last_idx], dataT[last_idx], dataP[last_idx], dataD[last_idx])

# Splitting the data into train and valid set. 
# Data before year is training and rest is validation/test

def train_valid_split(X, Y, time, geo, dguid, year):
    trainX = X[time < year + '-01']
    trainY = Y[time < year + '-01']
    trainT = time[time < year + '-01']
    trainP = geo[time < year + '-01']
    trainD = dguid[time < year + '-01']
    validX = X[time >= year + '-01']
    validY = Y[time >= year + '-01']
    validT = time[time >= year + '-01']
    validP = geo[time >= year + '-01']
    validD = dguid[time >= year + '-01']
    return [trainX, trainY, trainT, trainP, trainD, validX, validY, validT, validP, validD]
 
trainX, trainY, trainT, trainP, trainD, validX, validY, validT, validP, validD = train_valid_split(dataX, dataY, dataT, dataP, dataD, '2018')

# create and fit the LSTM RNN model
# input shape require a tuple (time-series length, Number of features)

def basic_model_lstm(look_back):
    t_model = Sequential()
    t_model.add(LSTM(256, return_sequences=False, input_shape=(look_back, len(feature_columns))))
    t_model.add(Dense(1))
    t_model.compile(
        loss='mean_squared_error',
        optimizer='adam',
        metrics=[metrics.mae])
    return(t_model)

model = basic_model_lstm(look_back)
model.summary()

epochs = 200
batch_size = 32

print('Epochs: ', epochs)
print('Batch size: ', batch_size)

# Training the LSTM RNN model

history = model.fit(trainX, trainY,
    batch_size=batch_size,
    epochs=epochs,
    shuffle=True,
    verbose=1, # Change it to 2, if wished to observe execution
    validation_data=(validX, validY))

# Print training and validation score
# Save the model and prediction

train_score = model.evaluate(trainX, trainY, verbose=0)
valid_score = model.evaluate(validX, validY, verbose=0)

print('Train MAE: ', round(train_score[1], 4), ', Train Loss: ', round(train_score[0], 4)) 
print('Val MAE: ', round(valid_score[1], 4), ', Val Loss: ', round(valid_score[0], 4))

valid_predict = model.predict(validX)
predicted_valid_df = pd.DataFrame({'REF_DATE': validT, 'DGUID': validD, 'predicted_total_house_index': model.predict(validX)[:, 0]})

train_predict = model.predict(trainX)
predicted_train_df = pd.DataFrame({'REF_DATE': trainT, 'DGUID': trainD, 'predicted_total_house_index': model.predict(trainX)[:, 0]})

predicted_df = pd.concat([predicted_train_df, predicted_valid_df])

model.save('Output/lstm_model.h5')
pd.merge(data, predicted_df, on=['REF_DATE', 'DGUID']).to_csv("Output/data_lstm.csv", header='true')

# Produce a plot for the validation/test results.

for dguid in province_dguid:
  plt.plot(validT[validD == dguid], validY[validD == dguid])
  plt.plot(validT[validD == dguid], valid_predict[validD == dguid])
  plt.ylabel('Total Housing Index')
  plt.legend(['Actual Index','Predicted Index'])
  plt.title('LSTM Model - {}'.format(validP[validD == dguid][0]))
  plt.xticks(rotation=45)
  plt.savefig('Output/plot/LSTM_{}.png'.format(validP[validD == dguid][0]))
  plt.xlabel('Time')
  plt.show()




